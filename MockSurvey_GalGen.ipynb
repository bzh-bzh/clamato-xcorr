{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in halo/stellar mass catalog from TreePM256 simulation, and generate mock survey data sets corresponding to that used in the CLAMATO2017 cross-correlation.\n",
    "\n",
    "Use stellar masses for the galaxy surveys estimated Yi-Kuan Chiang for an earlier iteration of the galaxy catalog (especially MOSDEF), so am manually scaling the numbers up to match the latest galaxy counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time as time\n",
    "import lyafxcorr_kg as xcorr\n",
    "\n",
    "# Set up matplotlib and use a nicer set of plot parameters\n",
    "%config InlineBackend.rc = {}\n",
    "import matplotlib as mpl\n",
    "mpl.rc('mathtext',fontset='stixsans')\n",
    "mpl.rc('figure', facecolor=\"white\")\n",
    "#matplotlib.rc_file(\"../../templates/matplotlibrc\")\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "from astropy.io import fits\n",
    "from astropy.io import ascii\n",
    "from astropy.table import Table\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "np.random.seed(452813501)\n",
    "outdir = '/Users/kheegan/lya/3d_recon/map2017/crosscorr/mocks/'\n",
    "\n",
    "# Define cosmology\n",
    "cosmo = FlatLambdaCDM(H0=70, Om0=0.31)\n",
    "zmin = 2.0\n",
    "zmid = 2.3\n",
    "comdist_mean = cosmo.comoving_distance(zmid)\n",
    "comdist_zmin = cosmo.comoving_distance(zmin)\n",
    "dcomdist_dz = cosmo.inv_efunc(zmid) *2998. # in Mpc/h\n",
    "\n",
    "# Galaxy survey parameters\n",
    "# Specify the [x,y] offsets of each survey relative to the field center, in Mpc/h, \n",
    "# and also a guess at the redshift offset and scatter\n",
    "dx_mosdef = (-8, 0.5)\n",
    "dy_mosdef = (-10, 11)\n",
    "deltaz_mosdef = -0.8\n",
    "sigz_mosdef = 1.5\n",
    "\n",
    "dx_zdeep = (-29, 29)\n",
    "dy_zdeep = (-26, 20)\n",
    "deltaz_zdeep = -1.8\n",
    "sigz_zdeep   = 3.\n",
    "\n",
    "dx_vuds = (-27, 15)\n",
    "dy_vuds = (-26, 22)\n",
    "deltaz_vuds = -1.\n",
    "sigz_vuds=3.\n",
    "\n",
    "dx_clamato = (-15, 15)\n",
    "dy_clamato = (-12,12)\n",
    "deltaz_clamato = -1.\n",
    "sigz_clamato=2.5\n",
    "\n",
    "dx_3dhst = (-8, 2)\n",
    "dy_3dhst = (-10, 13)\n",
    "deltaz_3dhst = -1\n",
    "sigz_3dhst = 11.\n",
    "\n",
    "def read_fofp_file(path):\n",
    "    \"\"\"\n",
    "    Read FoF properties file from the give path.\n",
    "    Just returns a tuple of masses and positions for now, but can be modified\n",
    "    easily.\n",
    "    Note that positions are in box size units.\n",
    "\n",
    "    \"\"\"\n",
    "    # get file handle\n",
    "    fof_file = open(path, \"r\")\n",
    "\n",
    "    # use fromfile to read binary chunks\n",
    "    # number of halos\n",
    "    num_groups = np.asscalar(np.fromfile(fof_file, dtype=\"i4\", count=1))\n",
    "    print(\"{} halos read\".format(num_groups))\n",
    "    # the mass in Msun/h\n",
    "    masses = np.fromfile(fof_file, dtype=\"f4\", count=num_groups)\n",
    "    sigma = np.fromfile(fof_file, dtype=\"f4\", count=num_groups)\n",
    "    v_circ = np.fromfile(fof_file, dtype=\"f4\", count=num_groups)\n",
    "    min_id = np.fromfile(fof_file, dtype=\"f4\", count=num_groups)\n",
    "    v_pot_e = np.fromfile(fof_file, dtype=\"f4\", count=num_groups)\n",
    "    positions = np.fromfile(fof_file, dtype=\"f4\", count=3*num_groups)\n",
    "\n",
    "    # done reading\n",
    "    fof_file.close()\n",
    "\n",
    "    # correct the shape\n",
    "    positions.shape = (num_groups, 3)\n",
    "\n",
    "    return (masses, positions)\n",
    "\n",
    "# Define methods that select galaxies within map boundaries for each survey. \n",
    "# Need to be able to handle period boundary conditions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fofp_path = 'treepm_stellar_masses/halos_z25.fofp'\n",
    "smass_path = 'treepm_stellar_masses/sm_moster_intrinsic_scatter.bin'\n",
    "\n",
    "masses, positions = read_fofp_file(fofp_path)\n",
    "\n",
    "smass_file = open(smass_path, \"r\")\n",
    "\n",
    "smass = np.fromfile(smass_file, count=len(masses))\n",
    "\n",
    "smass_file.close()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "subind = np.arange(len(smass))\n",
    "subind = np.random.choice(subind, 8000, replace='False')\n",
    "\n",
    "ax.scatter(masses[subind], smass[subind])\n",
    "ax.set_xscale(\"log\", nonposx='clip')\n",
    "ax.set_ylim([5,11])\n",
    "ax.set_title(\"With 'Intrinsic Scatter'\")\n",
    "ax.set_xlabel(\"Halo Mass\")\n",
    "ax.set_ylabel(\"Stellar Mass\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# The first entry in the file is a junk variable, and also turn h^{-1} M_sun into M_sun while we're at it\n",
    "positions = np.delete(positions,0,0)\n",
    "smass = np.delete(smass,0)\n",
    "masses = np.delete(masses,0)\n",
    "\n",
    "smass = smass - np.log10(cosmo.h)\n",
    "masses = masses/cosmo.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mstar = 8.\n",
    "max_mstar = 14.\n",
    "\n",
    "fig, (ax, ax2) = plt.subplots(1,2, figsize=(14,6))\n",
    "binsize=0.2\n",
    "\n",
    "# Shenanigans are being done here to try to get enough high-mass halos.\n",
    "# This is done with a combination of 'observational scatter' and outright moving \n",
    "# the entire distribution to higher mass\n",
    "obs_scatt = 0.55 \n",
    "smass_rand = smass + np.random.normal(0., obs_scatt, len(smass)) + 0.1\n",
    "histbins = np.arange(min_mstar,max_mstar+binsize, binsize)\n",
    "#print(histbins)\n",
    "ax.hist(smass_rand, bins=histbins, weights=np.ones(np.shape(smass),dtype='float')/80.)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('log stellar mass')\n",
    "ax.set_ylabel(r'Count in 0.2 $M_\\odot$ bins, rescaled to CLAMATO volume')\n",
    "\n",
    "ax.set_title('TreePM256 Simulation Halos')\n",
    "\n",
    "ax2.scatter(masses[subind], smass_rand[subind])\n",
    "ax2.set_xscale(\"log\", nonposx='clip')\n",
    "ax2.set_ylim([7,13.5])\n",
    "ax2.set_xlabel(\"Halo Mass\")\n",
    "ax2.set_ylabel(\"Stellar Mass\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gal_cat_fil = 'CLAMATO_2017_Cross-correlation_catalog_w_Mstar.txt'\n",
    "\n",
    "galcat = ascii.read(gal_cat_fil)\n",
    "\n",
    "get_mosdef = np.squeeze(np.where(galcat['source'].data == 'MOSDEF'))\n",
    "get_vuds = np.squeeze(np.where(galcat['source'].data == 'VUDS'))\n",
    "get_clamato = np.squeeze(np.where(galcat['source'].data == 'CLAMATO'))\n",
    "get_zdeep = np.squeeze(np.where(galcat['source'].data == 'zDeep'))\n",
    "get_3dhst = np.squeeze(np.where(galcat['source'].data == '3DHST'))\n",
    "\n",
    "mstars = galcat['mstar'].data\n",
    "\n",
    "mstars_mosdef = np.log10(mstars[get_mosdef])\n",
    "mstars_vuds = np.log10(mstars[get_vuds])\n",
    "mstars_clamato = np.log10(mstars[get_clamato])\n",
    "mstars_zdeep = np.log10(mstars[get_zdeep])\n",
    "mstars_3dhst = np.log10(mstars[get_3dhst])\n",
    "\n",
    "# limits for the histogram bins\n",
    "min_mstar = 7.\n",
    "max_mstar = 12.6\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "binsize=0.2\n",
    "\n",
    "histbins = np.arange(min_mstar,max_mstar+binsize, binsize)\n",
    "print(histbins)\n",
    "\n",
    "ax.hist(mstars_vuds[~np.isnan(mstars_vuds)], bins=histbins, histtype='step',fill=False, \n",
    "        color='blue',label='VUDS')\n",
    "ax.hist(mstars_mosdef[~np.isnan(mstars_mosdef)], bins = histbins, histtype='step', fill=False,\n",
    "        color='green',label='MOSDEF')\n",
    "ax.hist(mstars_zdeep[~np.isnan(mstars_zdeep)], bins = histbins, histtype='step', fill=False,\n",
    "        color='red', label='zDeep')\n",
    "ax.hist(mstars_clamato[~np.isnan(mstars_clamato)], bins = histbins, histtype='step', fill=False,\n",
    "        color='purple', label='CLAMATO')\n",
    "ax.hist(mstars_3dhst[~np.isnan(mstars_3dhst)], bins = histbins, histtype='step', fill=False,\n",
    "        color='black', label='3D-HST')\n",
    "\n",
    "ax.set_xlabel('log stellar mass')\n",
    "\n",
    "plt.legend(fontsize='small')\n",
    "plt.show()\n",
    "\n",
    "print('{} NaNs from MOSDEF galaxies'.format(np.sum(np.isnan(mstars_mosdef))))\n",
    "print('{} NaNs from VUDS galaxies'.format(np.sum(np.isnan(mstars_vuds))))\n",
    "print('{} NaNs from zDeep galaxies'.format(np.sum(np.isnan(mstars_zdeep))))\n",
    "print('{} NaNs from CLAMATO galaxies'.format(np.sum(np.isnan(mstars_clamato))))\n",
    "print('{} NaNs from 3D-HST galaxies'.format(np.sum(np.isnan(mstars_3dhst))))\n",
    "\n",
    "print('Median M_star = {} for MOSDEF'.format(np.median(mstars_mosdef[~np.isnan(mstars_mosdef)])))\n",
    "print('Median M_star = {} for VUDS'.format(np.median(mstars_vuds[~np.isnan(mstars_vuds)])))\n",
    "print('Median M_star = {} for zDeep'.format(np.median(mstars_zdeep[~np.isnan(mstars_zdeep)])))\n",
    "print('Median M_star = {} for CLAMATO'.format(np.median(mstars_clamato[~np.isnan(mstars_clamato)])))\n",
    "print('Median M_star = {} for 3D-HST'.format(np.median(mstars_3dhst[~np.isnan(mstars_3dhst)])))\n",
    "\n",
    "print('<M_star> = {} for MOSDEF'.format(np.mean(mstars_mosdef[~np.isnan(mstars_mosdef)])))\n",
    "print('<M_star> = {} for VUDS'.format(np.mean(mstars_vuds[~np.isnan(mstars_vuds)])))\n",
    "print('<M_star> = {} for zDeep'.format(np.mean(mstars_zdeep[~np.isnan(mstars_zdeep)])))\n",
    "print('<M_star> = {} for CLAMATO'.format(np.mean(mstars_clamato[~np.isnan(mstars_clamato)])))\n",
    "print('<M_star> = {} for 3D-HST'.format(np.mean(mstars_3dhst[~np.isnan(mstars_3dhst)])))\n",
    "\n",
    "# Calculate the histograms for later use\n",
    "hist_mosdef,binedges = np.histogram(mstars_mosdef[~np.isnan(mstars_mosdef)], \n",
    "                                    bins=histbins, density=False)\n",
    "hist_vuds,binedges   = np.histogram(mstars_vuds[~np.isnan(mstars_vuds)], \n",
    "                                    bins=histbins, density=False)\n",
    "hist_zdeep,binedges   = np.histogram(mstars_zdeep[~np.isnan(mstars_zdeep)], \n",
    "                                     bins=histbins, density=False)\n",
    "hist_clamato,binedges   = np.histogram(mstars_clamato[~np.isnan(mstars_clamato)], \n",
    "                                       bins=histbins, density=False)\n",
    "hist_3dhst,binedges   = np.histogram(mstars_3dhst[~np.isnan(mstars_3dhst)], \n",
    "                                     bins=histbins, density=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binctr = (binedges[:-1] + binedges[1:])/2.\n",
    "# Try to fit a polynomial to the MOSDEF distribution which is quite jagged\n",
    "xx = binctr[5:-2]\n",
    "print(xx)\n",
    "hist_tmp = hist_mosdef[5:-2]\n",
    "p_md = np.polyfit(xx, hist_tmp, 5)\n",
    "#polyfit =  p_md[0]*xx**4 + p_md[1]*xx**3 +p_md[2]*xx**2 + p_md[3]*xx + p_md[4]\n",
    "polyfit = p_md[0]*xx**5 + p_md[1]*xx**4 + p_md[2]*xx**3 +p_md[3]*xx**2 + p_md[4]*xx + p_md[5]\n",
    "\n",
    "# Manually fiddle with the fitted distribution :/\n",
    "polyfit[np.where(polyfit < 0)] = 0\n",
    "polyfit[0]=0\n",
    "polyfit[len(polyfit)-4]=0.7\n",
    "polyfit[len(polyfit)-3]=0.5\n",
    "\n",
    "print(np.sum(polyfit))\n",
    "print(len(mstars_mosdef[~np.isnan(mstars_mosdef)]))\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(mstars_mosdef[~np.isnan(mstars_mosdef)], bins = histbins, histtype='step', fill=False,\n",
    "        color='green',label='MOSDEF')\n",
    "ax.plot(xx, polyfit)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "hist_mosdef_fit = hist_mosdef.copy()\n",
    "hist_mosdef_fit[5:-2] = polyfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to fit a polynomial to the 3dhst distribution which is quite jagged\n",
    "xx = binctr[11:-4]\n",
    "print, xx\n",
    "hist_tmp = hist_3dhst[11:-4]\n",
    "p_3d = np.polyfit(xx, hist_tmp, 5)\n",
    "#polyfit =  p_md[0]*xx**4 + p_md[1]*xx**3 +p_md[2]*xx**2 + p_md[3]*xx + p_md[4]\n",
    "polyfit = p_3d[0]*xx**5 + p_3d[1]*xx**4 + p_3d[2]*xx**3 +p_3d[3]*xx**2 + p_3d[4]*xx + p_3d[5]\n",
    "\n",
    "# Manually fiddle with the fitted distribution :/\n",
    "polyfit[np.where(polyfit < 0)] = 0\n",
    "polyfit[0]=2\n",
    "polyfit[2] = polyfit[2]+2\n",
    "polyfit[3] = polyfit[3]+2\n",
    "polyfit[4:6] = polyfit[4:6]+1\n",
    "\n",
    "polyfit[-3] = polyfit[-3]-1\n",
    "polyfit[-4] = polyfit[-4]-1\n",
    "\n",
    "\n",
    "print(np.sum(polyfit))\n",
    "print(len(mstars_3dhst[~np.isnan(mstars_3dhst)]))\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(mstars_3dhst[~np.isnan(mstars_3dhst)], bins = histbins, histtype='step', fill=False,\n",
    "        color='green',label='3DHST')\n",
    "ax.plot(xx, polyfit)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "hist_3dhst_fit = hist_3dhst.copy()\n",
    "hist_3dhst_fit[11:-4] = polyfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale the numbers to match actual n_gal used in the cross-correlation\n",
    "ngal_mosdef = 195\n",
    "ngal_vuds = 435\n",
    "ngal_zdeep = 506\n",
    "ngal_clamato = 165\n",
    "ngal_3dhst = 322\n",
    "\n",
    "hist_mosdef = np.rint(hist_mosdef_fit * ngal_mosdef/np.sum(hist_mosdef_fit)).astype('int')\n",
    "hist_vuds = np.rint(hist_vuds * ngal_vuds/np.sum(hist_vuds)).astype('int')\n",
    "hist_zdeep = np.rint(hist_zdeep * ngal_zdeep/np.sum(hist_zdeep)).astype('int')\n",
    "hist_clamato = np.rint(hist_clamato * ngal_clamato/np.sum(hist_clamato)).astype('int')\n",
    "hist_3dhst = np.rint(hist_3dhst_fit * ngal_3dhst/np.sum(hist_3dhst_fit)).astype('int')\n",
    "\n",
    "print('{} galaxies from MOSDEF'.format(np.sum(hist_mosdef)))\n",
    "print('{} galaxies from VUDS'.format(np.sum(hist_vuds)))\n",
    "print('{} galaxies from zDeep'.format(np.sum(hist_zdeep)))\n",
    "print('{} galaxies from clamato'.format(np.sum(hist_clamato)))\n",
    "print('{} galaxies from 3dhst'.format(np.sum(hist_3dhst)))\n",
    "\n",
    "# Hack the histogram so that the high-mass end of the bins is effectively open-ended\n",
    "hist_mosdef_fit = hist_mosdef_fit[:-4]\n",
    "hist_vuds   = hist_vuds[:-4]\n",
    "hist_zdeep  = hist_zdeep[:-4]\n",
    "hist_clamato = hist_clamato[:-4]\n",
    "hist_3dhst_fit   = hist_3dhst_fit[:-4]\n",
    "binedges = binedges[:-4]\n",
    "binedges[-1]= 12.2\n",
    "\n",
    "nbins = len(hist_mosdef_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mock redshift catalogs\n",
    "\n",
    "# We will create mocks over these number of distinct fields\n",
    "nmock_x = 8\n",
    "nmock_y = 10\n",
    "nloop = 10\n",
    "nmocks = nmock_x * nmock_y * nloop\n",
    "\n",
    "width_x = 30. # Mpc/h\n",
    "width_y = 24. # Mpc/h\n",
    "\n",
    "# Generate lists indicating the CLAMATO field boundaries and centers\n",
    "xlow_field = np.arange(nmock_x)*width_x\n",
    "xhi_field = (np.arange(nmock_x) + 1.)*width_x \n",
    "xcen_field = np.ndarray.tolist((xlow_field+xhi_field)/2.)\n",
    "\n",
    "ylow_field = np.arange(nmock_y) * width_y\n",
    "yhi_field  = (np.arange(nmock_y)+1.)* width_y\n",
    "ycen_field = np.ndarray.tolist((ylow_field+yhi_field)/2.)\n",
    "\n",
    "# Grab all halos within this footprint\n",
    "xhalos = positions[:,0]*256.\n",
    "yhalos = positions[:,1]*256.\n",
    "zhalos = positions[:,2]*256.\n",
    "\n",
    "# Reflect the 4 sides + 4 corners in the [x,y] dimension\n",
    "xleft = xhalos-256.\n",
    "xright = xhalos+256.\n",
    "ytop = yhalos+256.\n",
    "ybottom=yhalos-256.\n",
    "\n",
    "xhalos = np.concatenate( (xhalos, xleft, xright,    xhalos,    xhalos,\n",
    "                         xleft, xright, xright, xleft) )\n",
    "yhalos = np.concatenate( (yhalos, yhalos,       yhalos,     ybottom, ytop,\n",
    "                         ybottom, ybottom, ytop, ytop) )\n",
    "zhalos = np.concatenate( (zhalos, zhalos,       zhalos,      zhalos,       zhalos,\n",
    "                         zhalos,   zhalos,     zhalos,       zhalos) )\n",
    "smass_rand=np.concatenate( (smass_rand, smass_rand, smass_rand, smass_rand, smass_rand,\n",
    "                           smass_rand,  smass_rand, smass_rand,  smass_rand))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping across the individual subvolumes, select halo from sim that matches each survey. We loop across the histogram bins in reverse order, and if there's a deficit in halos at the high mass then they will be made up in the lower-mass bins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_halos(hist_surv, dx_surv, dy_surv, delta_z, sigma_z):\n",
    "    \n",
    "    # Define field footprint\n",
    "    xlow_tmp, xhi_tmp = dx_surv \n",
    "    xlow_tmp += xcen_field_tmp\n",
    "    xhi_tmp  += xcen_field_tmp\n",
    "\n",
    "    ylow_tmp, yhi_tmp = dy_surv \n",
    "    ylow_tmp += ycen_field_tmp\n",
    "    yhi_tmp  += ycen_field_tmp\n",
    "\n",
    "    # Grab all halos within the present survey footprint\n",
    "    halos_here = np.all(np.column_stack([(xhalos > xlow_tmp), (xhalos <= xhi_tmp),\n",
    "                                         (yhalos > ylow_tmp), (yhalos <= yhi_tmp)]), \n",
    "                        axis=1)\n",
    "\n",
    "    nh_tmp = np.sum(halos_here)\n",
    "    #print('{} halos within footprint'.format(nh_tmp))\n",
    "\n",
    "    # Positions and stellar masses of all halos within footprint\n",
    "    xh_tmp = xhalos[halos_here]\n",
    "    yh_tmp = yhalos[halos_here]\n",
    "    zh_tmp = zhalos[halos_here]\n",
    "    smass_tmp = smass_rand[halos_here]\n",
    "        \n",
    "    # Here, we also move half of the halos to the extended, second z-half of the volume\n",
    "    ind_half_tmp = np.random.choice(np.arange(nh_tmp), \n",
    "                                    size=np.floor(0.5*nh_tmp).astype('int'), \n",
    "                                    replace=False)\n",
    "    zh_tmp[ind_half_tmp] = zh_tmp[ind_half_tmp] + 256.\n",
    "\n",
    "    #Initialize array to store indices of selected halos\n",
    "    mock_ind_surv = np.asarray([], dtype=np.int32)\n",
    "\n",
    "    # Select galaxies by mass by looping over histogram of desired survey\n",
    "    hist_surv_copy = hist_surv.copy()\n",
    "    ind_nonzero = np.where(hist_surv_copy > 0)[0] # List of nonzero array elements\n",
    "    for i in reversed(np.arange(nbins)):\n",
    "        if hist_surv_copy[i] != 0:\n",
    "            getmass, = np.where((smass_tmp > binedges[i]) & (smass_tmp <= binedges[i+1]))\n",
    "            if len(getmass) < hist_surv_copy[i]:\n",
    "\n",
    "                draw_massbin = getmass\n",
    "                # Distribute excess galaxy counts to lower mass bins\n",
    "                ct_excess = hist_surv_copy[i] - len(getmass)\n",
    "                #print(ct_excess)\n",
    "                draw_redist = np.random.choice(ind_nonzero[:i-1], size=ct_excess, \n",
    "                                               replace=True)\n",
    "                hist_surv_copy[draw_redist]+=1\n",
    "            else:\n",
    "                draw_massbin=np.random.choice(getmass, size=hist_surv_copy[i],\n",
    "                                              replace=False)\n",
    "            mock_ind_surv = np.append(mock_ind_surv, draw_massbin)\n",
    "        \n",
    "    xh_surv = xh_tmp[mock_ind_surv]\n",
    "    yh_surv = yh_tmp[mock_ind_surv]\n",
    "    # For z-dimension, also introduce redshift offset and scatter\n",
    "    zh_surv = zh_tmp[mock_ind_surv] + np.random.normal(delta_z, sigma_z, \n",
    "                                                       size=len(mock_ind_surv))\n",
    "\n",
    "    smass_surv = smass_tmp[mock_ind_surv]\n",
    "    return(xh_surv, yh_surv, zh_surv, smass_surv)\n",
    "        \n",
    "\n",
    "\n",
    "ngaldist_3dhst = np.asarray([], dtype=np.int32)\n",
    "ngaldist_mosdef = np.asarray([], dtype=np.int32)\n",
    "ngaldist_zdeep = np.asarray([], dtype=np.int32)\n",
    "ngaldist_vuds = np.asarray([], dtype=np.int32)\n",
    "ngaldist_clamato = np.asarray([], dtype=np.int32)\n",
    "\n",
    "ctr = 1\n",
    "tstart = time.time()\n",
    "\n",
    "for i in np.arange(nloop):\n",
    "    for xcen_field_tmp in xcen_field:\n",
    "        for ycen_field_tmp in ycen_field:\n",
    "        \n",
    "            x_3dhst, y_3dhst, z_3dhst, smass_3dhst = select_halos(hist_3dhst, dx_3dhst,\n",
    "                                                                 dy_3dhst, deltaz_mosdef,\n",
    "                                                                 sigz_3dhst)\n",
    "        \n",
    "            x_mosdef, y_mosdef, z_mosdef, smass_mosdef = select_halos(hist_mosdef, dx_mosdef, \n",
    "                                                                      dy_mosdef, \n",
    "                                                                      deltaz_mosdef, \n",
    "                                                                      sigz_mosdef)\n",
    "            x_zdeep, y_zdeep, z_zdeep, smass_zdeep = select_halos(hist_zdeep, dx_zdeep,\n",
    "                                                                 dy_zdeep, deltaz_zdeep,\n",
    "                                                                 sigz_zdeep)\n",
    "            x_vuds, y_vuds, z_vuds, smass_vuds = select_halos(hist_vuds, dx_vuds, \n",
    "                                                             dy_vuds, deltaz_vuds, \n",
    "                                                             sigz_vuds)\n",
    "            x_clamato, y_clamato, z_clamato, smass_clamato = \\\n",
    "            select_halos(hist_clamato, dx_clamato, dy_clamato, deltaz_clamato, sigz_clamato)\n",
    "        \n",
    "            ngal_3dhst = len(smass_3dhst)\n",
    "            ngal_mosdef = len(smass_mosdef)\n",
    "            ngal_zdeep = len(smass_zdeep)\n",
    "            ngal_vuds = len(smass_vuds)\n",
    "            ngal_clamato = len(smass_clamato)\n",
    "        \n",
    "            x_all = np.concatenate((x_3dhst, x_mosdef, x_zdeep, x_vuds, x_clamato))\n",
    "            y_all = np.concatenate((y_3dhst, y_mosdef, y_zdeep, y_vuds, y_clamato))\n",
    "            z_all = np.concatenate((z_3dhst, z_mosdef, z_zdeep, z_vuds, z_clamato))\n",
    "            smass_all = np.concatenate((smass_3dhst, smass_mosdef, smass_zdeep,\n",
    "                                    smass_vuds, smass_clamato))\n",
    "        \n",
    "            # Convert 3D positions in RA, Dec, and redshift\n",
    "            ra_all = 180./np.pi * x_all/comdist_mean.value/cosmo.h\n",
    "            dec_all = 180./np.pi * y_all/comdist_mean.value/cosmo.h\n",
    "            red_all = zmin + z_all/dcomdist_dz\n",
    "            # Generate array of survey names\n",
    "            source_all = np.concatenate((np.asarray(['3DHST']*ngal_3dhst),\n",
    "                                        np.asarray(['MOSDEF']*ngal_mosdef),\n",
    "                                        np.asarray(['zDeep']*ngal_zdeep),\n",
    "                                        np.asarray(['VUDS']*ngal_vuds),\n",
    "                                        np.asarray(['CLAMATO']*ngal_clamato)))\n",
    "        \n",
    "            # Output to file\n",
    "            output_table = Table([ra_all, dec_all, red_all, source_all, smass_all],\n",
    "                                names=('ra', 'dec', 'zspec', 'source', 'stellar_mass'),\n",
    "                                dtype=('f8', 'f8', 'f4', 'U', 'f8') )\n",
    "            output_table['ra'].unit=u.degree\n",
    "            output_table['dec'].unit = u.degree\n",
    "            outname = outdir + 'cat_galmock_nonuniq_{0:03d}.dat'.format(ctr)\n",
    "            ascii.write(output_table, outname, format='ipac', overwrite=True)\n",
    "        \n",
    "            # Build up histogram tracking the number of galaxies in each realization\n",
    "            ngaldist_3dhst = np.append(ngaldist_3dhst, ngal_3dhst)\n",
    "            ngaldist_mosdef = np.append(ngaldist_mosdef, ngal_mosdef)\n",
    "            ngaldist_zdeep = np.append(ngaldist_zdeep, ngal_zdeep)\n",
    "            ngaldist_vuds  = np.append(ngaldist_vuds, ngal_vuds)\n",
    "            ngaldist_clamato = np.append(ngaldist_clamato, ngal_clamato)\n",
    "        \n",
    "            if ctr ==1:\n",
    "                print('Time to generate one mock = {0}s'.format(time.time()-tstart))\n",
    "            print('i={0:d},x={1:5.2f} Mpc/h, y={2:5.2f} Mpc/h'.format(ctr,xcen_field_tmp, ycen_field_tmp))\n",
    "            ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist(ngaldist_3dhst, bins='auto', histtype='step')\n",
    "plt.show()\n",
    "\n",
    "print(np.mean(ngaldist_3dhst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist(ngaldist_mosdef, bins='auto', histtype='step')\n",
    "plt.show()\n",
    "\n",
    "print(np.mean(ngaldist_mosdef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for i in mock_ind_mosdef:\n",
    "#    print(xh_tmp[i], yh_tmp[i], zh_tmp[i])\n",
    "    \n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(14,6))\n",
    "\n",
    "ax1.scatter(x_3dhst, y_3dhst)\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_aspect('equal')\n",
    "\n",
    "ax2.hist(smass_3dhst, bins=binedges, histtype='step',fill=False, \n",
    "        color='blue')\n",
    "ax2.set_xlabel('log stellar mass')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(len(smass_3dhst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in mock_ind_mosdef:\n",
    "#    print(xh_tmp[i], yh_tmp[i], zh_tmp[i])\n",
    "    \n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(14,6))\n",
    "\n",
    "ax1.scatter(x_mosdef, y_mosdef)\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_aspect('equal')\n",
    "\n",
    "ax2.hist(smass_mosdef, bins=binedges, histtype='step',fill=False, \n",
    "        color='blue')\n",
    "ax2.set_xlabel('log stellar mass')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(len(smass_mosdef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clamato-xcorr",
   "language": "python",
   "name": "clamato-xcorr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
