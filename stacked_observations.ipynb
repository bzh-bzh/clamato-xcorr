{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring the Galaxy-LyaForest Cross-Correlation from CLAMATO DR2\n",
    "\n",
    "Here, we carry out the first cross-correlation measurement of the Ly-alpha forest measured by CLAMATO DR2, and coeval galaxies from MOSDEF, 3D-HST and zCOSMOS-Deep (separately for each sample). We use the simple estimator from Font-Ribera+ 2012 DLA-Forest cross-correlation paper:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\xi_A = \\frac{\\sum_{i\\in A} w_i \\delta_{Fi}}{\\sum_{i\\in A} w_i},\n",
    "\\end{equation*}\n",
    "\n",
    "where \n",
    "\n",
    "\\begin{equation*}\n",
    "w_i =  \\left[\\sigma^2_F(z_i) + \\frac{\\sigma_{N,i}^2}{C_i^2 \\bar{F}^2(z_i)}\\right]^{-1}\n",
    "\\end{equation*}\n",
    "\n",
    "and $\\sigma_F^2(z_i) = 0.065 [(1+z_i)/3.25]^{3.8}$.\n",
    "\n",
    "This uses the np.histogram2d function twice, to compute the numerator and denominator of the estimator around each galaxy.\n",
    "\n",
    "The pixel data needs to be generated using the IDL script GEN_CROSSCORR_INPUT.PRO, and the mean-flux shoudl first be calculated with CALC_MEANFLUX.IPYNB\n",
    "\n",
    "### Read in Ly-a forest pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time as time\n",
    "import os\n",
    "\n",
    "import lyafxcorr_kg as xcorr\n",
    "import constants\n",
    "constants.DATA_VERSION = 'v0'\n",
    "\n",
    "import pandas as pd\n",
    "# Set up matplotlib and use a nicer set of plot parameters\n",
    "%config InlineBackend.rc = {}\n",
    "import matplotlib as mpl\n",
    "mpl.rc('mathtext',fontset='stixsans')\n",
    "mpl.rc('figure', facecolor=\"white\")\n",
    "#matplotlib.rc_file(\"../../templates/matplotlibrc\")\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "\n",
    "import astropy.table\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "from astropy.io import fits\n",
    "from astropy.io import ascii\n",
    "from astropy.table import Table\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "import plotting\n",
    "plotting.plot_preamble()\n",
    "\n",
    "def taueff_evo(z):\n",
    "    return 0.001845 * (1.+z)**3.924\n",
    "\n",
    "# Define cosmology\n",
    "cosmo = constants.COSMOLOGY\n",
    "zmin = 2.0\n",
    "zmid = 2.3\n",
    "comdist_mean = cosmo.comoving_distance(zmid)\n",
    "comdist_zmin = cosmo.comoving_distance(zmin)\n",
    "dcomdist_dz = cosmo.inv_efunc(zmid) *2998. # in Mpc/h\n",
    "sim_boxlen_mpch = 250\n",
    "\n",
    "dz_to_dmpch = lambda z: z * dcomdist_dz\n",
    "dkms_to_dmpch = lambda v: ((v * u.km / u.s) / cosmo.H(zmid)).value * cosmo.h * (1 + zmid)\n",
    "\n",
    "lyapix = xcorr.lyapix(os.path.join(constants.CLAMATO_DIR_BASE, f\"pixel_radecz_cl2020_{constants.DATA_VERSION}.bin\") ,cosmo=cosmo)\n",
    "\n",
    "print(\"Read in %i Ly-a forest pixels\" % lyapix.npix)\n",
    "npix = lyapix.npix\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "binwidth = 50\n",
    "histdata = lyapix.coord.distance.value\n",
    "\n",
    "ax.hist(histdata,bins=np.arange(min(histdata),max(histdata) + binwidth, binwidth))\n",
    "plt.show()\n",
    "\n",
    "# Carry out mean-flux correction\n",
    "fmean_str = ascii.read(os.path.join(constants.CLAMATO_DIR_BASE, f'fmean_measured_{constants.DATA_VERSION}.dat'))\n",
    "zmid = fmean_str['zmid']\n",
    "F_mean = fmean_str['F_mean']\n",
    "\n",
    "#Fcorr = np.interp(lyapix.z, zmid, F_mean) / np.exp(-taueff_evo(lyapix.z))\n",
    "#lyapix.delta = ((1.+lyapix.delta)/np.exp(-taueff_evo(lyapix.z)))-1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in galaxies and generate randoms\n",
    "We use the catalog created with GRAB_COEVAL_GAL.IPYNB\n",
    "\n",
    "At the same time, also generate mock catalog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galfil = os.path.join(constants.GAL_DIR_BASE, f'cat_galxcorr_cl2020_uniq_{constants.DATA_VERSION}.dat')\n",
    "gal = ascii.read(galfil, format='ipac')\n",
    "\n",
    "#nonuniq_gal = ascii.read(os.path.join(constants.GAL_DIR_BASE, f'cat_galxcorr_cl2020_nonuniq_{constants.DATA_VERSION}.dat'), format='ipac')\n",
    "\n",
    "# Drop ZFIRE galaxies. And also 3DHST\n",
    "included_surveys = ['CLAMATO', 'MOSDEF', 'VUDS', 'zDeep']\n",
    "indices_to_drop = []\n",
    "for i in range(len(gal)):\n",
    "    if gal[i]['source'] not in included_surveys:\n",
    "        indices_to_drop.append(i)\n",
    "gal.remove_rows(indices_to_drop)\n",
    "\n",
    "# indices_to_drop = []\n",
    "# for i in range(len(nonuniq_gal)):\n",
    "#     if nonuniq_gal[i]['source'] not in included_surveys:\n",
    "#         indices_to_drop.append(i)\n",
    "# nonuniq_gal.remove_rows(indices_to_drop)\n",
    "\n",
    "print(f'Stacked catalog has {len(gal)} galaxies')\n",
    "\n",
    "specz_cat = ascii.read(os.path.join(constants.GAL_DIR_BASE, 'all_specz_v3_comb_COSMOS2020_v3.dat'))\n",
    "\n",
    "indices_to_drop = []\n",
    "for i in range(len(specz_cat)):\n",
    "    if specz_cat[i]['source'] not in included_surveys:\n",
    "        indices_to_drop.append(i)\n",
    "specz_cat.remove_rows(indices_to_drop)\n",
    "\n",
    "del specz_cat['id']\n",
    "del specz_cat['zspec']\n",
    "specz_cat.rename_column('ID_specz', 'id')\n",
    "specz_cat['id'] = specz_cat['id'].astype(int)\n",
    "\n",
    "gal = astropy.table.join(gal, specz_cat, keys='id')\n",
    "\n",
    "print(f'After stellar mass join, galaxy catalog has {len(gal)} galaxies.')\n",
    "\n",
    "# Use best-fit (minimum chi2) stellar masses. KG says best-fit, and also probably not much difference.\n",
    "log_smass_obs = gal['Ms_best']\n",
    "\n",
    "# Drop the two galaxies which have negative log masses.\n",
    "print(f'{np.sum(log_smass_obs <= 0)} galaxies have negative log stellar masses; dropping.')\n",
    "print(f'{np.sum(np.isnan(log_smass_obs))} galaxies have NaN stellar masses; also dropping these.')\n",
    "gal = gal[log_smass_obs > 0]\n",
    "log_smass_obs = log_smass_obs[log_smass_obs > 0]\n",
    "\n",
    "print(f'After drops, final stacked catalog has {len(gal)} galaxies.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(len(nonuniq_gal))\n",
    "# print(len(set(nonuniq_gal['id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot histogram of stellar masses\n",
    "plt.hist(log_smass_obs, bins=50);\n",
    "plt.xlabel('Best fit log stellar mass [M_sun]')\n",
    "plt.ylabel('# galaxies')\n",
    "# plt.axvline(np.percentile(log_smass_obs, 25), color='black')\n",
    "# plt.axvline(np.percentile(log_smass_obs, 50), color='black')\n",
    "# plt.axvline(np.percentile(log_smass_obs, 75), color='black', label='25/50/75 percentiles')\n",
    "\n",
    "plt.axvline(np.percentile(log_smass_obs, 33.3), color='black')\n",
    "plt.axvline(np.percentile(log_smass_obs, 66.6), color='black', label='33.3/66.6 percentiles')\n",
    "\n",
    "print(np.percentile(log_smass_obs, 33.3), np.percentile(log_smass_obs, 66.6))\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(log_smass_obs < 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot histogram of stellar masses\n",
    "fig, ax = plt.subplots(1, 2, figsize=(9, 3.5), sharey=True)\n",
    "# plt.figure(figsize=(5,3.5))\n",
    "\n",
    "survey_names = sorted(list(set(gal['source_1'])))\n",
    "survey_smass = [log_smass_obs[gal['source_1'] == s] for s in survey_names]\n",
    "survey_rmag = [gal[gal['source_1'] == s]['rmag'] for s in survey_names]\n",
    "\n",
    "plt.sca(ax[0])\n",
    "print(f'{np.sum(gal[\"rmag\"] < 0)} gals have -99 (blank) R-band magnitude.')\n",
    "min_nonneg_rmag = np.min(gal[gal['rmag'] > 0]['rmag'])\n",
    "plt.hist(survey_rmag, stacked=True, bins=50, alpha=0.4, label=survey_names, range=(min_nonneg_rmag, np.max(gal['rmag'])))\n",
    "plt.xlabel('HSC r-band apparent magnitude')\n",
    "plt.ylabel(r'$N_{gal}$')\n",
    "\n",
    "plt.sca(ax[1])\n",
    "plt.hist(survey_smass, stacked=True, bins=50, alpha=0.4, label=survey_names)\n",
    "# for s in set(gal['source_1']):\n",
    "#     plt.hist(log_smass_obs[gal['source_1'] == s], bins=50, alpha=0.4, label=s)\n",
    "plt.xlabel(r'$\\log_{10}(M_* / M_\\odot)$')\n",
    "# plt.axvline(np.percentile(log_smass_obs, 25), color='black')\n",
    "# plt.axvline(np.percentile(log_smass_obs, 50), color='black')\n",
    "# plt.axvline(np.percentile(log_smass_obs, 75), color='black', label='25/50/75 percentiles')\n",
    "\n",
    "plt.axvline(np.percentile(log_smass_obs, 33.3), color='black', ls='--')\n",
    "plt.axvline(np.percentile(log_smass_obs, 66.6), color='black', ls='--')#, label='33.3/66.6 percentiles')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(constants.FIG_DIR_BASE, 'split-gal-sample.png'), dpi=200)\n",
    "plt.savefig(os.path.join(constants.FIG_DIR_BASE, 'split-gal-sample.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(gal['rmag'] < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(gal[gal['rmag'] < 0]['source_1'] == 'MOSDEF'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smass_bin_boundaries = [-np.inf, np.quantile(log_smass_obs, 1/3), np.quantile(log_smass_obs, 2/3), np.inf]\n",
    "\n",
    "bin_titles = constants.STACKED_BIN_TITLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate \"combined\" mock z-dispersion & offset\n",
    "\n",
    "For the bias-HM pipeline where we use Vega mocks, since our combined bias is across surveys, draw a z-offset/disp using the mock covar parameters (close to fitted values), then try fitting a combined Gaussian to the combined unique catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# v14-final from mocksurvey_galgen.ipynb\n",
    "survey_zparams = {\n",
    "    'MOSDEF':  (-0.84, 1.91),\n",
    "    'zDeep':   (-1.87, 3.88),\n",
    "    # These differ from above 'converged' values since they're the output posteriors of the above values.\n",
    "    'VUDS':    (-2.36, 2.64),\n",
    "    'CLAMATO': (-2.12, 2.20),\n",
    "}\n",
    "\n",
    "rng = np.random.default_rng(seed=4892347589)\n",
    "\n",
    "survey_ngal = {k: np.sum(gal['source_1'] == k) for k in survey_zparams.keys()}\n",
    "print(survey_ngal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combined_survey_realization():\n",
    "    z_samples = []\n",
    "    for s, (mean, sig) in survey_zparams.items():\n",
    "        z_samples.append(rng.normal(loc=mean, scale=sig, size=survey_ngal[s]))\n",
    "    return np.concatenate(z_samples)\n",
    "\n",
    "n_realizations = 1000\n",
    "\n",
    "bootstrap_combined_survey_z = np.concatenate([combined_survey_realization() for _ in range(n_realizations)])\n",
    "\n",
    "plt.hist(bootstrap_combined_survey_z, bins=100);\n",
    "\n",
    "print(np.mean(bootstrap_combined_survey_z), np.std(bootstrap_combined_survey_z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in bin edges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PiBin_fil = os.path.join(constants.XCORR_DIR_BASE, 'bins23_pi_0-30hMpc.txt')\n",
    "SigBin_fil = os.path.join(constants.XCORR_DIR_BASE, 'bins10_sigma_0-30hMpc.txt')\n",
    "\n",
    "PiBins0 = ascii.read(PiBin_fil)\n",
    "SigBins0 = ascii.read(SigBin_fil)\n",
    "\n",
    "PiEdges = PiBins0['pi_edges'].data\n",
    "SigEdges = SigBins0['sigma_edges'].data\n",
    "\n",
    "# Convert bin boundaries from Mpc/h to Mpc\n",
    "PiEdges  = PiEdges/(len(PiEdges)*[cosmo.h])\n",
    "SigEdges = SigEdges/(len(SigEdges)*[cosmo.h])\n",
    "\n",
    "print('Pi bin edges in Mpc:')\n",
    "print(PiEdges)\n",
    "print('Sigma bin edges in Mpc:')\n",
    "print(SigEdges)\n",
    "\n",
    "\n",
    "PiBound = (min(PiEdges), max(PiEdges) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Cross-Correlation For Stellar Mass Bins (Stacked catalog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.join(constants.XCORR_DIR_BASE, 'stacked')\n",
    "\n",
    "binned_Coord = []\n",
    "\n",
    "for i in range(len(smass_bin_boundaries) - 1):\n",
    "    lb, ub = smass_bin_boundaries[i], smass_bin_boundaries[i + 1]\n",
    "    mask = (log_smass_obs >= lb) & (log_smass_obs < ub)\n",
    "    masked_cat = gal[mask]\n",
    "    avg_smass = np.mean(log_smass_obs[mask])\n",
    "    print(f'Log smass {lb} - {ub} | # gal {np.sum(mask)} | Average log smass {avg_smass} | Median log smass {np.median(log_smass_obs[mask])}')\n",
    "    binned_Coord.append((lb, ub, avg_smass, SkyCoord(ra=masked_cat['ra'], dec=masked_cat['dec'],\n",
    "                                                     distance=cosmo.comoving_distance(masked_cat['zspec']))))\n",
    "\n",
    "for (smass_lb, smass_ub, avg_smass, Coord), title in zip(binned_Coord, bin_titles):\n",
    "    XCorr, _ = xcorr.xcorr_gal_lya(Coord, lyapix, SigEdges, PiEdges, cosmo=cosmo)\n",
    "    np.save(os.path.join(base_dir, f\"xcorr_stacked_{title}_globalf_{constants.DATA_VERSION}.npy\"), XCorr.value)\n",
    "        \n",
    "    # Plotting code. For 1D, since 2D cross-correlations are sus due to mixing different surveys.\n",
    "    SigCenters = (SigEdges[1:] + SigEdges[:-1]) / 2\n",
    "    \n",
    "    plt.plot(SigCenters, np.sum(XCorr, axis=1), label=f'{avg_smass:.2f}')\n",
    "\n",
    "plt.xlabel(r'$\\sigma\\; (\\mathrm{cMpc})$')\n",
    "plt.ylabel('Parallel-summed cross-correlation')\n",
    "plt.legend(title='Average log-smass of bin [M_sun]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Cross-Correlation For Stellar Mass Bins (Separate surveys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Of interest because fitted bias is very low. Want to see if it lies within the COSTCO-I footprint.\n",
    "mosdef_medium_mask = None\n",
    "\n",
    "for survey in included_surveys:\n",
    "    survey_filename_fmt = survey.lower() if survey != 'zDeep' else survey\n",
    "    base_dir = os.path.join(constants.XCORR_DIR_BASE, 'split')\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    binned_Coord = []\n",
    "    bin_proportions = []\n",
    "    for i in range(len(smass_bin_boundaries) - 1):\n",
    "        lb, ub = smass_bin_boundaries[i], smass_bin_boundaries[i + 1]\n",
    "        mask = (log_smass_obs >= lb) & (log_smass_obs < ub)\n",
    "        mask = mask & (gal['source_1'] == survey)\n",
    "        if i == 1 and survey == 'MOSDEF':\n",
    "            mosdef_medium_mask = mask\n",
    "        masked_cat = gal[mask]\n",
    "        avg_smass = np.mean(log_smass_obs[mask])\n",
    "        print(f'Survey {survey} | Log smass {lb} - {ub} | # gal {np.sum(mask)} | Median log smass {np.median(log_smass_obs[mask])} ')\n",
    "        binned_Coord.append((lb, ub, avg_smass, SkyCoord(ra=masked_cat['ra'], dec=masked_cat['dec'],\n",
    "                                                         distance=cosmo.comoving_distance(masked_cat['zspec']))))\n",
    "        bin_proportions.append(np.sum(mask) / np.sum(gal['source_1'] == survey))\n",
    "    assert np.isclose(np.sum(bin_proportions), 1)\n",
    "    print(bin_proportions)\n",
    "\n",
    "    for (smass_lb, smass_ub, avg_smass, Coord), bin_prop, title in zip(binned_Coord, bin_proportions, bin_titles):\n",
    "        XCorr, _ = xcorr.xcorr_gal_lya(Coord, lyapix, SigEdges, PiEdges, cosmo=cosmo)\n",
    "        np.save(os.path.join(base_dir, f\"xcorr_{survey_filename_fmt}_{title}_globalf_{constants.DATA_VERSION}.npy\"), XCorr.value)\n",
    "        np.save(os.path.join(base_dir, f\"binprop_{survey_filename_fmt}_{title}_{constants.DATA_VERSION}.npy\"), bin_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do MOSDEF medium-mass galaxies lie close to COSTCO-I?\n",
    "\n",
    "Since we find that the bias for this bin/survey specifically is very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "costco_gal_cat = pd.read_csv(os.path.join(constants.GAL_DIR_BASE, 'COSTCO_I_member.csv'))\n",
    "costco_gal_cat['ID'] = costco_gal_cat['ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mosdef_medium_gal = gal[mosdef_medium_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mosdef_medium_gal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "costco_gal_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do any IDs match?\n",
    "print(costco_gal_cat['ID'].isin(mosdef_medium_gal['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Are MOSDEF medium-mass galaxies close to the COSTCO cluster?\n",
    "costco_skycoord = SkyCoord(ra=150.11 * u.deg, dec=2.161 * u.deg, distance=dz_to_dmpch(2.298) / cosmo.h * u.Mpc)\n",
    "\n",
    "costco_gal_skycoord = SkyCoord(ra=costco_gal_cat['RA'] * u.deg, dec=costco_gal_cat['Dec'] * u.deg, distance=dz_to_dmpch(costco_gal_cat['zspec']) / cosmo.h * u.Mpc)\n",
    "\n",
    "mosdef_medium_skycoord = SkyCoord(ra=mosdef_medium_gal['ra'], dec=mosdef_medium_gal['dec'], distance=dz_to_dmpch(mosdef_medium_gal['zspec']) / cosmo.h * u.Mpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "costco_skycoord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "costco_gal_skycoord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted(costco_skycoord.separation_3d(costco_gal_skycoord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sorted(costco_skycoord.separation_3d(mosdef_medium_skycoord).to(u.Mpc).value))\n",
    "plt.hist(costco_skycoord.separation_3d(mosdef_medium_skycoord).to(u.Mpc).value);\n",
    "plt.xlabel('3D separation between COSTCO-I protocluster center and MOSDEF medium-mass galaxies (Mpc)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(costco_skycoord.separation(mosdef_medium_skycoord).to(u.deg).value);\n",
    "plt.xlabel('Angular separation between COSTCO-I protocluster center and MOSDEF medium-mass galaxies (deg)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZFIRE Protocluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zfire_skycoord = SkyCoord(ra=150.094 * u.deg, dec=2.251 * u.deg, distance=dz_to_dmpch(2.095) / cosmo.h * u.Mpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sorted(zfire_skycoord.separation_3d(mosdef_medium_skycoord).to(u.Mpc).value))\n",
    "plt.hist(zfire_skycoord.separation_3d(mosdef_medium_skycoord).to(u.Mpc).value);\n",
    "plt.xlabel('3D separation between ZFIRE protocluster center and MOSDEF medium-mass galaxies (Mpc)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clamato-xcorr",
   "language": "python",
   "name": "clamato-xcorr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
