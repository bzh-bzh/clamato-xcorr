{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring the Galaxy-LyaForest Cross-Correlation from CLAMATO DR2\n",
    "\n",
    "Here, we carry out the first cross-correlation measurement of the Ly-alpha forest measured by CLAMATO DR2, and coeval galaxies from MOSDEF, 3D-HST and zCOSMOS-Deep (separately for each sample). We use the simple estimator from Font-Ribera+ 2012 DLA-Forest cross-correlation paper:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\xi_A = \\frac{\\sum_{i\\in A} w_i \\delta_{Fi}}{\\sum_{i\\in A} w_i},\n",
    "\\end{equation*}\n",
    "\n",
    "where \n",
    "\n",
    "\\begin{equation*}\n",
    "w_i =  \\left[\\sigma^2_F(z_i) + \\frac{\\sigma_{N,i}^2}{C_i^2 \\bar{F}^2(z_i)}\\right]^{-1}\n",
    "\\end{equation*}\n",
    "\n",
    "and $\\sigma_F^2(z_i) = 0.065 [(1+z_i)/3.25]^{3.8}$.\n",
    "\n",
    "This uses the np.histogram2d function twice, to compute the numerator and denominator of the estimator around each galaxy.\n",
    "\n",
    "The pixel data needs to be generated using the IDL script GEN_CROSSCORR_INPUT.PRO, and the mean-flux shoudl first be calculated with CALC_MEANFLUX.IPYNB\n",
    "\n",
    "### Read in Ly-a forest pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time as time\n",
    "import os\n",
    "\n",
    "import lyafxcorr_kg as xcorr\n",
    "import constants\n",
    "\n",
    "# Set up matplotlib and use a nicer set of plot parameters\n",
    "%config InlineBackend.rc = {}\n",
    "import matplotlib as mpl\n",
    "mpl.rc('mathtext',fontset='stixsans')\n",
    "mpl.rc('figure', facecolor=\"white\")\n",
    "#matplotlib.rc_file(\"../../templates/matplotlibrc\")\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "\n",
    "import astropy.table\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "from astropy.io import fits\n",
    "from astropy.io import ascii\n",
    "from astropy.table import Table\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "def taueff_evo(z):\n",
    "    return 0.001845 * (1.+z)**3.924\n",
    "\n",
    "# Define cosmology\n",
    "cosmo = constants.COSMOLOGY\n",
    "\n",
    "lyapix = xcorr.lyapix(os.path.join(constants.CLAMATO_DIR_BASE, f\"pixel_radecz_cl2020_{constants.DATA_VERSION}.bin\") ,cosmo=cosmo)\n",
    "\n",
    "print(\"Read in %i Ly-a forest pixels\" % lyapix.npix)\n",
    "npix = lyapix.npix\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "binwidth = 50\n",
    "histdata = lyapix.coord.distance.value\n",
    "\n",
    "ax.hist(histdata,bins=np.arange(min(histdata),max(histdata) + binwidth, binwidth))\n",
    "plt.show()\n",
    "\n",
    "# Carry out mean-flux correction\n",
    "fmean_str = ascii.read(os.path.join(constants.CLAMATO_DIR_BASE, f'fmean_measured_{constants.DATA_VERSION}.dat'))\n",
    "zmid = fmean_str['zmid']\n",
    "F_mean = fmean_str['F_mean']\n",
    "\n",
    "#Fcorr = np.interp(lyapix.z, zmid, F_mean) / np.exp(-taueff_evo(lyapix.z))\n",
    "#lyapix.delta = ((1.+lyapix.delta)/np.exp(-taueff_evo(lyapix.z)))-1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in galaxies and generate randoms\n",
    "We use the catalog created with GRAB_COEVAL_GAL.IPYNB\n",
    "\n",
    "At the same time, also generate mock catalog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galfil = os.path.join(constants.GAL_DIR_BASE, f'cat_galxcorr_cl2020_uniq_{constants.DATA_VERSION}.dat')\n",
    "gal = ascii.read(galfil, format='ipac')\n",
    "\n",
    "# Drop ZFIRE galaxies.\n",
    "included_surveys = ['3DHST', 'CLAMATO', 'MOSDEF', 'VUDS', 'zDeep']\n",
    "indices_to_drop = []\n",
    "for i in range(len(gal)):\n",
    "    if gal[i]['source'] not in included_surveys:\n",
    "        indices_to_drop.append(i)\n",
    "gal.remove_rows(indices_to_drop)\n",
    "\n",
    "print(f'Stacked catalog has {len(gal)} galaxies')\n",
    "\n",
    "specz_cat = ascii.read(os.path.join(constants.GAL_DIR_BASE, 'all_specz_v3_comb_COSMOS2020_v3.dat'))\n",
    "\n",
    "indices_to_drop = []\n",
    "for i in range(len(specz_cat)):\n",
    "    if specz_cat[i]['source'] not in included_surveys:\n",
    "        indices_to_drop.append(i)\n",
    "specz_cat.remove_rows(indices_to_drop)\n",
    "\n",
    "del specz_cat['id']\n",
    "del specz_cat['zspec']\n",
    "specz_cat.rename_column('ID_specz', 'id')\n",
    "specz_cat['id'] = specz_cat['id'].astype(int)\n",
    "\n",
    "gal = astropy.table.join(gal, specz_cat, keys='id')\n",
    "\n",
    "print(f'After stellar mass join, galaxy catalog has {len(gal)} galaxies.')\n",
    "\n",
    "# Use best-fit (minimum chi2) stellar masses. KG says best-fit, and also probably not much difference.\n",
    "log_smass_obs = gal['Ms_best']\n",
    "\n",
    "# Drop the two galaxies which have negative log masses.\n",
    "print(f'{np.sum(log_smass_obs <= 0)} galaxies have negative log stellar masses; dropping.')\n",
    "print(f'{np.sum(np.isnan(log_smass_obs))} galaxies have NaN stellar masses; also dropping these.')\n",
    "gal = gal[log_smass_obs > 0]\n",
    "log_smass_obs = log_smass_obs[log_smass_obs > 0]\n",
    "\n",
    "print(f'After drops, final stacked catalog has {len(gal)} galaxies.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot histogram of stellar masses\n",
    "plt.hist(log_smass_obs, bins=50);\n",
    "plt.xlabel('Best fit log stellar mass [M_sun]')\n",
    "plt.ylabel('# galaxies')\n",
    "# plt.axvline(np.percentile(log_smass_obs, 25), color='black')\n",
    "# plt.axvline(np.percentile(log_smass_obs, 50), color='black')\n",
    "# plt.axvline(np.percentile(log_smass_obs, 75), color='black', label='25/50/75 percentiles')\n",
    "\n",
    "plt.axvline(np.percentile(log_smass_obs, 33.3), color='black')\n",
    "plt.axvline(np.percentile(log_smass_obs, 66.6), color='black', label='33.3/66.6 percentiles')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smass_bin_boundaries = [-np.inf, np.quantile(log_smass_obs, 1/3), np.quantile(log_smass_obs, 2/3), np.inf]\n",
    "\n",
    "binned_Coord = []\n",
    "\n",
    "for i in range(len(smass_bin_boundaries) - 1):\n",
    "    lb, ub = smass_bin_boundaries[i], smass_bin_boundaries[i + 1]\n",
    "    mask = (log_smass_obs >= lb) & (log_smass_obs < ub)\n",
    "    masked_cat = gal[mask]\n",
    "    avg_smass = np.mean(log_smass_obs[mask])\n",
    "    print(f'Log smass {lb} - {ub} | # gal {np.sum(mask)} | Average log smass {avg_smass}')\n",
    "    binned_Coord.append((lb, ub, avg_smass, SkyCoord(ra=masked_cat['ra'], dec=masked_cat['dec'],\n",
    "                                                     distance=cosmo.comoving_distance(masked_cat['zspec']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in bin edges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PiBin_fil = os.path.join(constants.XCORR_DIR_BASE, 'bins23_pi_0-30hMpc.txt')\n",
    "SigBin_fil = os.path.join(constants.XCORR_DIR_BASE, 'bins10_sigma_0-30hMpc.txt')\n",
    "\n",
    "PiBins0 = ascii.read(PiBin_fil)\n",
    "SigBins0 = ascii.read(SigBin_fil)\n",
    "\n",
    "PiEdges = PiBins0['pi_edges'].data\n",
    "SigEdges = SigBins0['sigma_edges'].data\n",
    "\n",
    "# Convert bin boundaries from Mpc/h to Mpc\n",
    "PiEdges  = PiEdges/(len(PiEdges)*[cosmo.h])\n",
    "SigEdges = SigEdges/(len(SigEdges)*[cosmo.h])\n",
    "\n",
    "print('Pi bin edges in Mpc:')\n",
    "print(PiEdges)\n",
    "print('Sigma bin edges in Mpc:')\n",
    "print(SigEdges)\n",
    "\n",
    "\n",
    "PiBound = (min(PiEdges), max(PiEdges) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Cross-Correlation For Stellar Mass Bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.join(constants.XCORR_DIR_BASE, 'stacked')\n",
    "\n",
    "for smass_lb, smass_ub, avg_smass, Coord in binned_Coord:\n",
    "    XCorr, _ = xcorr.xcorr_gal_lya(Coord, lyapix, SigEdges, PiEdges, cosmo=cosmo)\n",
    "    np.save(os.path.join(base_dir, f\"xcorr_stacked_{avg_smass}_globalf_{constants.DATA_VERSION}.npy\"), XCorr.value)\n",
    "    \n",
    "    # Plotting code\n",
    "    X, Y = np.meshgrid(SigEdges, PiEdges)\n",
    "\n",
    "    XCorrArr = np.rot90(XCorr)\n",
    "    XCorrArr = np.flipud(XCorrArr)\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    ax1 = plt.gca()\n",
    "\n",
    "    SigMax = 25.\n",
    "    PiMin = -30.\n",
    "    PiMax = 30.\n",
    "\n",
    "    pcm=ax1.pcolormesh(X, Y, XCorrArr,cmap='jet_r',vmin=-0.2, vmax=0.15 )\n",
    "    ax1.set_aspect('equal')\n",
    "    ax1.set_xlim(np.min(X), SigMax)\n",
    "    ax1.set_ylim(PiMin, PiMax)\n",
    "    ax1.set_xlabel(r'$\\sigma\\; (\\mathrm{cMpc})$')\n",
    "    ax1.set_ylabel(r'$\\pi\\; (\\mathrm{cMpc})$')\n",
    "    ax1.set_title(f'Stacked {smass_lb} - {smass_ub}')\n",
    "\n",
    "    fig.colorbar(pcm, ax=ax1)\n",
    "    fig.subplots_adjust(wspace=-0.2)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clamato-xcorr",
   "language": "python",
   "name": "clamato-xcorr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
